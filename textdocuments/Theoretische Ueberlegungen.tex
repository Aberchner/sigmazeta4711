\documentclass[11pt]{scrartcl}
\usepackage{amsmath}
\begin{document}
	\section{Martingale und Varianten}
		\subsection{Einführung in Martingale}
			Man betrachte zunächst ein Spiel bei dem auf Sieg und Niederlage gewettet werden kann. Die Wahrscheinlichkeit für einen Sieg sei also \(p_{0}\) und eine Niederlage \(p_{1}\) (Meist gilt hier \(p_{0} = 1-p_{1}\)). Am Anfang des Spiels legt sich der Spieler auf Sieg oder Niederlage fest. Sei dies hier o.B.d.A. Sieg. In der ersten Runde setzt der Spieler also einen Betrag \(x_{1}\)  auf Sieg. Bei einer Niederlage wird wiederholt auf Sieg gesetzt und der Betrag vervielfacht, d.h. \(\alpha x_{i} = x_{i+1}\). In den bekanntesten Varianten wird hier \(\alpha = 2\) gewaehlt. Sobald auf einer Stufe ein Sieg eintritt, wird in der nächsten Runde wieder mit \(x_{0}\) gestartet. \(\alpha\) sollte also so gewählt sein das es möglich ist auf jeder Stufe durch einen Sieg den Verlust der vorherigen Stufen auszugleichen.
		\subsection{Verallgemeinertes Martingale}
			In diesem Abschnitt soll Martingale auf (Aktien-)Kurse angewendet und verallgemeinert werden. Dafuer seien im Folgendem \(p_{1}, p_{2}, \cdots,p_{n}\) die Wahrscheinlichkeiten fuer das steigen eines Kurses. Des weiteren seien \(x_{1}, x_{2}, \cdots,x_{n}\) die jeweiligen Einsaetze und X der zugehoerige Vektor, \(\gamma\) der Gewinnfaktor (d.h. der Gewinn bei einem Sieg auf der i-ten Stufen beträgt \(\gamma x_{i}\)) und \(\alpha_{1}, \alpha_{2}, \cdots,\alpha_{n}\) die Steigerungsfaktoren (d.h. \(\alpha_{i}x_{i}=x_{i+1}\)).\\\\
			D.h. der Gewinn auf der i-ten Stufe entspricht entweder \(-x_{i}\) oder \(\gamma x_{i}\). Sei also \(\psi(p_{i})\) dieser Gewinn. Dann gilt fuer den Erwartungswert
			\begin{center}
				\[E(X)=\sum_{i=1}^n \psi(p_{i})p_{i}\]
			\end{center}
			Und fuer jeden Einsatz gilt
			\begin{center}
				\[x_{k}=\alpha_{k-1}x_{k-1}=\alpha_{k-1}\alpha_{k-2}x_{k-2}=\cdots=\prod_{i=1}^{k-1}\alpha_{i}x_{1}\]
			\end{center}
			Sei \(\omega\) der maximale zur Verfuegung stehende Betrag, d.h
			\begin{center}
				\[\omega \geq \sum_{i=1}^{n}x_{i}=\sum_{i=1}^{n}\prod_{k=1}^{i-1}\alpha_{k}x_{1}\]
			\end{center}
			Das Ziel ist jetzt also den Erwartungswert nach den Einsaetzen zu optimieren und nach Strategien in Abhaengigkeit von den Gewinnwahrscheinlichkeiten zu finden.\\
			Berechne zunaechst also den Gradienten von E
			\begin{center}
				\[(\nabla E)_{i}=\sum_{k=1}^{n}\frac{d\psi(p_{k})p_{k}}{dx_{i}}=\frac{d\psi(p_{i})p_{i}}{dx_{i}}\]
			\end{center}
			Falls \(\psi(p_{i})=-x_{i}\) gilt
			\begin{center}
				\[(\nabla E)_{i}=\frac{d\psi(p_{i})p_{i}}{dx_{i}}=-\frac{dx_{i}p_{i}}{dx_{i}}=-p_{i}\]
			\end{center}
			und falls \(\psi(p_{i})=\gamma x_{i}\) gilt
			\begin{center}
				\[(\nabla E)_{i}=\frac{d\psi(p_{i})p_{i}}{dx_{i}}=\frac{d\gamma x_{i}p_{i}}{dx_{i}}=\gamma p_{i}\]
			\end{center}
			Sei also im Folgendem
			\begin{center}
				\[ \xi(i) :=
					\begin{cases}
						-1, & \psi(p_{i})=-x_{i} \\
						\gamma, & \psi(p_{i})=\gamma x_{i}
					\end{cases}
				\]
			\end{center}
			mit dem Gradienten des Erwartungswerts
			\begin{center}
				\[(\nabla E)_{i}=\xi(i)p_{i}\]
			\end{center}
			Setze nun die Nebenbedingung als die Norm von X\[g(X):=\sum_{i=1}^{n}x_{i}^2-{\omega}^2\]
			Dann gilt fuer \[(\nabla \lambda g)_{i} = 2\lambda x_{i}\]\\
			Es laesst sich also mit der Methode der Lagrange-Multiplikatoren die folgende Funktion aufstellen \[\Lambda(X,\lambda) := E(X)+\lambda g(X)\]
			\[\nabla \Lambda(X,\lambda) = \nabla E(X) + \nabla \lambda g(X)\]
			Durch die bereits berechneten Gradienten folgt
			\[(\nabla \Lambda (X,\lambda))_{k}=
				\begin{cases}
					\xi (k)p_{k}+2\lambda x_{k}, & 1\leq k\leq n\\
					\sum_{i=1}^{n}x_{i}^2-\omega^2, & k = n+1
				\end{cases}\]
			und es muss gelten das
			\[\nabla \Lambda(X,\lambda)=0\]
			Daher folgt
			\[\lambda x_{i} = -\frac{\xi(i)p_{i}}{2}\]
			Durch die Methode der Lagrange-Multiplikatoren koennen wir annehmen das \(\lambda \neq 0\)
			\[x_{i}= -\frac{\xi(i)p_{i}}{2\lambda}\]
			Jetzt kann jedes x in die letzte Gleichung eingesetzt werden
			\[\sum_{i=1}^{n}(-\frac{\xi(i)p_{i}}{2\lambda})^2-\omega^2=0\]
			\[\sum_{i=1}^{n}\frac{\xi(i)^2p_{i}^2}{4\lambda^2}=\omega^2\]
			\[\sum_{i=1}^{n}\xi(i)^2p_{i}^2=4\omega^2\lambda^2\]
			\[\lambda = \sum_{i=1}^{n}\frac{\xi(i)^2p_{i}^2}{4\omega^2}\]
			Eingesetzt in die anderen n Gleichungen folgt
			\[x_{i}=-\frac{2\omega^2\xi_{i}p_{i}}{\sum_{k=1}^{n}\xi(k)^2p_{k}^2}\]

			
\end{document}